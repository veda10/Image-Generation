{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "q1-gan-Copy1.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "M_fxplbwke7Y",
        "colab_type": "code",
        "outputId": "86b6e8a1-9cf7-4153-f1cc-46546d4910dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler \n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tCZxY5qwke7f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 32\n",
        "b_1 = 0.5\n",
        "b_2 = 0.999\n",
        "learning_rate = 0.001\n",
        "interval = 100\n",
        "img_shape = (3, 200, 180)\n",
        "latent_dim = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RozWmlBOke7i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "os.makedirs(\"images\", exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qa1PL-Dzke7p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(np.prod(img_shape)), 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(128, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        \n",
        "        img_flat = img.view(img.shape[0], -1)\n",
        "        valid = self.model(img_flat)\n",
        "\n",
        "        return valid"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R4G_4X4zke7m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        def block(in_feat, out_feat, normalize=True):\n",
        "            layers = [nn.Linear(in_feat, out_feat)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(latent_dim, 128, normalize=False),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            *block(512, 1024),\n",
        "            nn.Linear(1024, int(np.prod(img_shape))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "        self.avgpool =  nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        img = img.view(img.size(0), *img_shape)\n",
        "        return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Ext7GEQke7t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "adversarial_loss = torch.nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "40A_1TW4ke7w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "26W8nY8Ske71",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(b_1, b_2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(b_1, b_2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8WWWpJoBke75",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Tensor = torch.FloatTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d7ucX-gQke7_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "root_dir = 'drive/My Drive/dl/faces94'\n",
        "files = glob(f\"{root_dir}/**/**/*.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hmqvK8Uike8F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "c_2_i = {\n",
        "    \"female\": 0,\n",
        "    \"male\":1,\n",
        "    \"malestaff\": 2 \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "54fjagu2ke8I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "transform_loader = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5],[0.5])\n",
        "])\n",
        "\n",
        "all_imgs = torch.stack([transform_loader(Image.open(x)) for x in files])\n",
        "all_label = torch.tensor([c_2_i[x.split('/')[-3]] for x in files])\n",
        "\n",
        "train_idx, test_idx = train_test_split(range(len(all_imgs)), test_size=0.2, random_state=102)\n",
        "\n",
        "train_img = all_imgs[train_idx]\n",
        "train_label = all_label[train_idx]\n",
        "\n",
        "test_img = all_imgs[test_idx]\n",
        "test_label = all_label[test_idx]\n",
        "\n",
        "train_data = TensorDataset(train_img, train_label)\n",
        "test_data = TensorDataset(test_img, test_label)\n",
        "\n",
        "train_samp = RandomSampler(train_data)\n",
        "test_samp = SequentialSampler(test_data)\n",
        "\n",
        "train_loader = DataLoader(train_data, sampler=train_samp, batch_size=32)\n",
        "test_loader = DataLoader(test_data, sampler=test_samp, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vvIThg25ke8L",
        "colab_type": "code",
        "outputId": "4d240e9c-adaa-4cbe-b930-64d0ccf810e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 13107
        }
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    for i, (imgs,_) in enumerate(train_loader):\n",
        "        \n",
        "        #imgs = imgs.view(imgs.shape[0],-1)\n",
        "        valid = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "        \n",
        "        #print(real_imgs)\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(z)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Measure discriminator's ability to classify real from generated samples\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        print(\n",
        "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "            % (epoch, epochs, i, len(train_loader), d_loss.item(), g_loss.item())\n",
        "        )\n",
        "\n",
        "        batches_done = epoch * len(train_loader) + i\n",
        "        if batches_done % interval == 0:\n",
        "            save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0/10] [Batch 0/77] [D loss: 0.682875] [G loss: 0.680957]\n",
            "[Epoch 0/10] [Batch 1/77] [D loss: 0.333611] [G loss: 0.719765]\n",
            "[Epoch 0/10] [Batch 2/77] [D loss: 0.417878] [G loss: 0.569668]\n",
            "[Epoch 0/10] [Batch 3/77] [D loss: 0.456333] [G loss: 0.519606]\n",
            "[Epoch 0/10] [Batch 4/77] [D loss: 0.377083] [G loss: 0.649505]\n",
            "[Epoch 0/10] [Batch 5/77] [D loss: 0.089746] [G loss: 1.815386]\n",
            "[Epoch 0/10] [Batch 6/77] [D loss: 11.898030] [G loss: 3.903816]\n",
            "[Epoch 0/10] [Batch 7/77] [D loss: 4.725320] [G loss: 0.000124]\n",
            "[Epoch 0/10] [Batch 8/77] [D loss: 5.521926] [G loss: 0.000029]\n",
            "[Epoch 0/10] [Batch 9/77] [D loss: 3.895155] [G loss: 0.000530]\n",
            "[Epoch 0/10] [Batch 10/77] [D loss: 1.589377] [G loss: 0.044157]\n",
            "[Epoch 0/10] [Batch 11/77] [D loss: 1.879678] [G loss: 1.232162]\n",
            "[Epoch 0/10] [Batch 12/77] [D loss: 1.347934] [G loss: 0.070874]\n",
            "[Epoch 0/10] [Batch 13/77] [D loss: 1.195582] [G loss: 0.097419]\n",
            "[Epoch 0/10] [Batch 14/77] [D loss: 0.440988] [G loss: 0.535077]\n",
            "[Epoch 0/10] [Batch 15/77] [D loss: 0.124170] [G loss: 1.919529]\n",
            "[Epoch 0/10] [Batch 16/77] [D loss: 0.465369] [G loss: 1.827814]\n",
            "[Epoch 0/10] [Batch 17/77] [D loss: 1.027168] [G loss: 0.137177]\n",
            "[Epoch 0/10] [Batch 18/77] [D loss: 1.050447] [G loss: 0.130590]\n",
            "[Epoch 0/10] [Batch 19/77] [D loss: 0.793902] [G loss: 0.323081]\n",
            "[Epoch 0/10] [Batch 20/77] [D loss: 1.399887] [G loss: 0.063086]\n",
            "[Epoch 0/10] [Batch 21/77] [D loss: 1.312111] [G loss: 0.075649]\n",
            "[Epoch 0/10] [Batch 22/77] [D loss: 0.939314] [G loss: 0.166275]\n",
            "[Epoch 0/10] [Batch 23/77] [D loss: 0.609116] [G loss: 0.354800]\n",
            "[Epoch 0/10] [Batch 24/77] [D loss: 0.892167] [G loss: 0.665588]\n",
            "[Epoch 0/10] [Batch 25/77] [D loss: 0.969467] [G loss: 0.156915]\n",
            "[Epoch 0/10] [Batch 26/77] [D loss: 1.068337] [G loss: 0.126799]\n",
            "[Epoch 0/10] [Batch 27/77] [D loss: 0.922552] [G loss: 0.173175]\n",
            "[Epoch 0/10] [Batch 28/77] [D loss: 0.642936] [G loss: 0.323902]\n",
            "[Epoch 0/10] [Batch 29/77] [D loss: 0.372416] [G loss: 0.644416]\n",
            "[Epoch 0/10] [Batch 30/77] [D loss: 0.399176] [G loss: 1.182625]\n",
            "[Epoch 0/10] [Batch 31/77] [D loss: 0.386495] [G loss: 0.619706]\n",
            "[Epoch 0/10] [Batch 32/77] [D loss: 0.379948] [G loss: 0.631667]\n",
            "[Epoch 0/10] [Batch 33/77] [D loss: 0.264985] [G loss: 0.893409]\n",
            "[Epoch 0/10] [Batch 34/77] [D loss: 0.450034] [G loss: 1.298710]\n",
            "[Epoch 0/10] [Batch 35/77] [D loss: 0.782271] [G loss: 0.236525]\n",
            "[Epoch 0/10] [Batch 36/77] [D loss: 0.824723] [G loss: 0.214750]\n",
            "[Epoch 0/10] [Batch 37/77] [D loss: 0.523785] [G loss: 0.433040]\n",
            "[Epoch 0/10] [Batch 38/77] [D loss: 0.698549] [G loss: 0.908295]\n",
            "[Epoch 0/10] [Batch 39/77] [D loss: 1.076917] [G loss: 0.125945]\n",
            "[Epoch 0/10] [Batch 40/77] [D loss: 0.885368] [G loss: 0.187882]\n",
            "[Epoch 0/10] [Batch 41/77] [D loss: 0.451755] [G loss: 0.522900]\n",
            "[Epoch 0/10] [Batch 42/77] [D loss: 0.725762] [G loss: 1.403529]\n",
            "[Epoch 0/10] [Batch 43/77] [D loss: 0.836985] [G loss: 0.208351]\n",
            "[Epoch 0/10] [Batch 44/77] [D loss: 0.679017] [G loss: 0.297605]\n",
            "[Epoch 0/10] [Batch 45/77] [D loss: 0.350709] [G loss: 0.688587]\n",
            "[Epoch 0/10] [Batch 46/77] [D loss: 0.335774] [G loss: 1.468980]\n",
            "[Epoch 0/10] [Batch 47/77] [D loss: 0.322953] [G loss: 0.743987]\n",
            "[Epoch 0/10] [Batch 48/77] [D loss: 0.306877] [G loss: 0.797359]\n",
            "[Epoch 0/10] [Batch 49/77] [D loss: 0.281879] [G loss: 0.977424]\n",
            "[Epoch 0/10] [Batch 50/77] [D loss: 0.303304] [G loss: 0.956407]\n",
            "[Epoch 0/10] [Batch 51/77] [D loss: 0.373604] [G loss: 0.641993]\n",
            "[Epoch 0/10] [Batch 52/77] [D loss: 0.264256] [G loss: 0.894165]\n",
            "[Epoch 0/10] [Batch 53/77] [D loss: 0.196404] [G loss: 1.250173]\n",
            "[Epoch 0/10] [Batch 54/77] [D loss: 0.199265] [G loss: 1.148473]\n",
            "[Epoch 0/10] [Batch 55/77] [D loss: 0.523913] [G loss: 1.063330]\n",
            "[Epoch 0/10] [Batch 56/77] [D loss: 1.125944] [G loss: 0.112323]\n",
            "[Epoch 0/10] [Batch 57/77] [D loss: 0.680329] [G loss: 0.297615]\n",
            "[Epoch 0/10] [Batch 58/77] [D loss: 0.258960] [G loss: 0.931152]\n",
            "[Epoch 0/10] [Batch 59/77] [D loss: 0.771560] [G loss: 2.036114]\n",
            "[Epoch 0/10] [Batch 60/77] [D loss: 0.882736] [G loss: 0.189476]\n",
            "[Epoch 0/10] [Batch 61/77] [D loss: 0.744729] [G loss: 0.256728]\n",
            "[Epoch 0/10] [Batch 62/77] [D loss: 0.420943] [G loss: 0.563920]\n",
            "[Epoch 0/10] [Batch 63/77] [D loss: 0.259896] [G loss: 1.209118]\n",
            "[Epoch 0/10] [Batch 64/77] [D loss: 0.272096] [G loss: 1.343021]\n",
            "[Epoch 0/10] [Batch 65/77] [D loss: 0.297503] [G loss: 0.804778]\n",
            "[Epoch 0/10] [Batch 66/77] [D loss: 0.295470] [G loss: 0.814701]\n",
            "[Epoch 0/10] [Batch 67/77] [D loss: 0.275460] [G loss: 0.959480]\n",
            "[Epoch 0/10] [Batch 68/77] [D loss: 0.529138] [G loss: 0.828973]\n",
            "[Epoch 0/10] [Batch 69/77] [D loss: 0.549459] [G loss: 0.407600]\n",
            "[Epoch 0/10] [Batch 70/77] [D loss: 0.454793] [G loss: 0.517608]\n",
            "[Epoch 0/10] [Batch 71/77] [D loss: 0.349600] [G loss: 0.731386]\n",
            "[Epoch 0/10] [Batch 72/77] [D loss: 0.486063] [G loss: 1.010022]\n",
            "[Epoch 0/10] [Batch 73/77] [D loss: 0.463525] [G loss: 0.505159]\n",
            "[Epoch 0/10] [Batch 74/77] [D loss: 0.342927] [G loss: 0.700943]\n",
            "[Epoch 0/10] [Batch 75/77] [D loss: 0.294913] [G loss: 1.177223]\n",
            "[Epoch 0/10] [Batch 76/77] [D loss: 0.562475] [G loss: 0.393382]\n",
            "[Epoch 1/10] [Batch 0/77] [D loss: 0.344871] [G loss: 0.696998]\n",
            "[Epoch 1/10] [Batch 1/77] [D loss: 0.229286] [G loss: 1.512707]\n",
            "[Epoch 1/10] [Batch 2/77] [D loss: 0.308975] [G loss: 0.785427]\n",
            "[Epoch 1/10] [Batch 3/77] [D loss: 0.384949] [G loss: 1.038319]\n",
            "[Epoch 1/10] [Batch 4/77] [D loss: 0.445099] [G loss: 0.548698]\n",
            "[Epoch 1/10] [Batch 5/77] [D loss: 0.427276] [G loss: 0.852696]\n",
            "[Epoch 1/10] [Batch 6/77] [D loss: 0.496188] [G loss: 0.715282]\n",
            "[Epoch 1/10] [Batch 7/77] [D loss: 0.674290] [G loss: 0.302193]\n",
            "[Epoch 1/10] [Batch 8/77] [D loss: 0.391931] [G loss: 0.613704]\n",
            "[Epoch 1/10] [Batch 9/77] [D loss: 0.155490] [G loss: 1.344222]\n",
            "[Epoch 1/10] [Batch 10/77] [D loss: 0.581740] [G loss: 2.173973]\n",
            "[Epoch 1/10] [Batch 11/77] [D loss: 1.049971] [G loss: 0.138775]\n",
            "[Epoch 1/10] [Batch 12/77] [D loss: 1.117136] [G loss: 0.139350]\n",
            "[Epoch 1/10] [Batch 13/77] [D loss: 0.448038] [G loss: 0.546602]\n",
            "[Epoch 1/10] [Batch 14/77] [D loss: 0.823963] [G loss: 1.742762]\n",
            "[Epoch 1/10] [Batch 15/77] [D loss: 1.603081] [G loss: 0.151709]\n",
            "[Epoch 1/10] [Batch 16/77] [D loss: 1.616723] [G loss: 0.163705]\n",
            "[Epoch 1/10] [Batch 17/77] [D loss: 1.148804] [G loss: 0.240272]\n",
            "[Epoch 1/10] [Batch 18/77] [D loss: 1.155851] [G loss: 0.820965]\n",
            "[Epoch 1/10] [Batch 19/77] [D loss: 1.359135] [G loss: 0.110111]\n",
            "[Epoch 1/10] [Batch 20/77] [D loss: 1.129047] [G loss: 0.147047]\n",
            "[Epoch 1/10] [Batch 21/77] [D loss: 0.521694] [G loss: 0.751028]\n",
            "[Epoch 1/10] [Batch 22/77] [D loss: 1.459660] [G loss: 2.417663]\n",
            "[Epoch 1/10] [Batch 23/77] [D loss: 1.505144] [G loss: 0.063719]\n",
            "[Epoch 1/10] [Batch 24/77] [D loss: 1.166454] [G loss: 0.109186]\n",
            "[Epoch 1/10] [Batch 25/77] [D loss: 1.102370] [G loss: 0.164123]\n",
            "[Epoch 1/10] [Batch 26/77] [D loss: 0.435982] [G loss: 0.590154]\n",
            "[Epoch 1/10] [Batch 27/77] [D loss: 2.883940] [G loss: 1.989857]\n",
            "[Epoch 1/10] [Batch 28/77] [D loss: 2.154493] [G loss: 0.039714]\n",
            "[Epoch 1/10] [Batch 29/77] [D loss: 1.505393] [G loss: 0.069161]\n",
            "[Epoch 1/10] [Batch 30/77] [D loss: 0.465567] [G loss: 0.847492]\n",
            "[Epoch 1/10] [Batch 31/77] [D loss: 1.458787] [G loss: 2.178408]\n",
            "[Epoch 1/10] [Batch 32/77] [D loss: 1.167202] [G loss: 0.107958]\n",
            "[Epoch 1/10] [Batch 33/77] [D loss: 1.267292] [G loss: 0.101388]\n",
            "[Epoch 1/10] [Batch 34/77] [D loss: 1.061929] [G loss: 0.153832]\n",
            "[Epoch 1/10] [Batch 35/77] [D loss: 0.782455] [G loss: 0.252131]\n",
            "[Epoch 1/10] [Batch 36/77] [D loss: 0.504759] [G loss: 0.476108]\n",
            "[Epoch 1/10] [Batch 37/77] [D loss: 1.874072] [G loss: 1.210638]\n",
            "[Epoch 1/10] [Batch 38/77] [D loss: 1.756844] [G loss: 0.046986]\n",
            "[Epoch 1/10] [Batch 39/77] [D loss: 2.115800] [G loss: 0.027079]\n",
            "[Epoch 1/10] [Batch 40/77] [D loss: 1.499418] [G loss: 0.067638]\n",
            "[Epoch 1/10] [Batch 41/77] [D loss: 0.740045] [G loss: 0.284377]\n",
            "[Epoch 1/10] [Batch 42/77] [D loss: 0.617197] [G loss: 1.090709]\n",
            "[Epoch 1/10] [Batch 43/77] [D loss: 0.600435] [G loss: 0.379324]\n",
            "[Epoch 1/10] [Batch 44/77] [D loss: 0.504902] [G loss: 0.517400]\n",
            "[Epoch 1/10] [Batch 45/77] [D loss: 0.720918] [G loss: 0.947255]\n",
            "[Epoch 1/10] [Batch 46/77] [D loss: 1.244440] [G loss: 0.188317]\n",
            "[Epoch 1/10] [Batch 47/77] [D loss: 1.260513] [G loss: 0.179605]\n",
            "[Epoch 1/10] [Batch 48/77] [D loss: 1.814538] [G loss: 1.232219]\n",
            "[Epoch 1/10] [Batch 49/77] [D loss: 4.534192] [G loss: 0.011801]\n",
            "[Epoch 1/10] [Batch 50/77] [D loss: 3.994743] [G loss: 0.012012]\n",
            "[Epoch 1/10] [Batch 51/77] [D loss: 1.952814] [G loss: 0.075260]\n",
            "[Epoch 1/10] [Batch 52/77] [D loss: 1.246968] [G loss: 3.450254]\n",
            "[Epoch 1/10] [Batch 53/77] [D loss: 1.384354] [G loss: 0.327300]\n",
            "[Epoch 1/10] [Batch 54/77] [D loss: 1.833987] [G loss: 0.053011]\n",
            "[Epoch 1/10] [Batch 55/77] [D loss: 1.051018] [G loss: 0.205383]\n",
            "[Epoch 1/10] [Batch 56/77] [D loss: 0.561007] [G loss: 0.510293]\n",
            "[Epoch 1/10] [Batch 57/77] [D loss: 1.193179] [G loss: 1.169829]\n",
            "[Epoch 1/10] [Batch 58/77] [D loss: 1.336110] [G loss: 0.129381]\n",
            "[Epoch 1/10] [Batch 59/77] [D loss: 1.488934] [G loss: 0.092709]\n",
            "[Epoch 1/10] [Batch 60/77] [D loss: 0.669569] [G loss: 0.323622]\n",
            "[Epoch 1/10] [Batch 61/77] [D loss: 0.540856] [G loss: 0.857295]\n",
            "[Epoch 1/10] [Batch 62/77] [D loss: 0.429653] [G loss: 0.661454]\n",
            "[Epoch 1/10] [Batch 63/77] [D loss: 0.418060] [G loss: 0.644058]\n",
            "[Epoch 1/10] [Batch 64/77] [D loss: 0.381207] [G loss: 0.805063]\n",
            "[Epoch 1/10] [Batch 65/77] [D loss: 0.403793] [G loss: 0.752070]\n",
            "[Epoch 1/10] [Batch 66/77] [D loss: 0.390057] [G loss: 0.667026]\n",
            "[Epoch 1/10] [Batch 67/77] [D loss: 0.392945] [G loss: 0.853086]\n",
            "[Epoch 1/10] [Batch 68/77] [D loss: 0.454269] [G loss: 0.595589]\n",
            "[Epoch 1/10] [Batch 69/77] [D loss: 0.408496] [G loss: 0.784134]\n",
            "[Epoch 1/10] [Batch 70/77] [D loss: 0.422587] [G loss: 0.709141]\n",
            "[Epoch 1/10] [Batch 71/77] [D loss: 0.520091] [G loss: 0.825974]\n",
            "[Epoch 1/10] [Batch 72/77] [D loss: 1.175311] [G loss: 0.184437]\n",
            "[Epoch 1/10] [Batch 73/77] [D loss: 0.770194] [G loss: 0.905587]\n",
            "[Epoch 1/10] [Batch 74/77] [D loss: 1.176876] [G loss: 0.175295]\n",
            "[Epoch 1/10] [Batch 75/77] [D loss: 0.645169] [G loss: 1.038321]\n",
            "[Epoch 1/10] [Batch 76/77] [D loss: 0.823121] [G loss: 0.506836]\n",
            "[Epoch 2/10] [Batch 0/77] [D loss: 0.654020] [G loss: 2.526733]\n",
            "[Epoch 2/10] [Batch 1/77] [D loss: 1.171730] [G loss: 0.144601]\n",
            "[Epoch 2/10] [Batch 2/77] [D loss: 0.631767] [G loss: 0.379024]\n",
            "[Epoch 2/10] [Batch 3/77] [D loss: 0.633363] [G loss: 0.985623]\n",
            "[Epoch 2/10] [Batch 4/77] [D loss: 0.562801] [G loss: 0.411702]\n",
            "[Epoch 2/10] [Batch 5/77] [D loss: 0.563929] [G loss: 0.463243]\n",
            "[Epoch 2/10] [Batch 6/77] [D loss: 0.385589] [G loss: 0.866502]\n",
            "[Epoch 2/10] [Batch 7/77] [D loss: 0.459129] [G loss: 1.000552]\n",
            "[Epoch 2/10] [Batch 8/77] [D loss: 0.570425] [G loss: 0.543088]\n",
            "[Epoch 2/10] [Batch 9/77] [D loss: 0.689561] [G loss: 0.965228]\n",
            "[Epoch 2/10] [Batch 10/77] [D loss: 1.117097] [G loss: 0.184974]\n",
            "[Epoch 2/10] [Batch 11/77] [D loss: 0.746176] [G loss: 2.083021]\n",
            "[Epoch 2/10] [Batch 12/77] [D loss: 0.547903] [G loss: 0.429042]\n",
            "[Epoch 2/10] [Batch 13/77] [D loss: 0.394253] [G loss: 0.667189]\n",
            "[Epoch 2/10] [Batch 14/77] [D loss: 0.664790] [G loss: 1.480786]\n",
            "[Epoch 2/10] [Batch 15/77] [D loss: 0.727544] [G loss: 0.418338]\n",
            "[Epoch 2/10] [Batch 16/77] [D loss: 0.603871] [G loss: 0.398873]\n",
            "[Epoch 2/10] [Batch 17/77] [D loss: 0.382974] [G loss: 0.799426]\n",
            "[Epoch 2/10] [Batch 18/77] [D loss: 0.466336] [G loss: 1.027362]\n",
            "[Epoch 2/10] [Batch 19/77] [D loss: 0.724541] [G loss: 0.345445]\n",
            "[Epoch 2/10] [Batch 20/77] [D loss: 0.532897] [G loss: 0.716391]\n",
            "[Epoch 2/10] [Batch 21/77] [D loss: 0.747001] [G loss: 0.812749]\n",
            "[Epoch 2/10] [Batch 22/77] [D loss: 1.421758] [G loss: 0.233221]\n",
            "[Epoch 2/10] [Batch 23/77] [D loss: 0.694038] [G loss: 0.528963]\n",
            "[Epoch 2/10] [Batch 24/77] [D loss: 0.825622] [G loss: 3.017179]\n",
            "[Epoch 2/10] [Batch 25/77] [D loss: 1.291862] [G loss: 0.191377]\n",
            "[Epoch 2/10] [Batch 26/77] [D loss: 0.872002] [G loss: 0.214875]\n",
            "[Epoch 2/10] [Batch 27/77] [D loss: 0.369374] [G loss: 1.492758]\n",
            "[Epoch 2/10] [Batch 28/77] [D loss: 0.551390] [G loss: 1.758214]\n",
            "[Epoch 2/10] [Batch 29/77] [D loss: 0.570583] [G loss: 0.414275]\n",
            "[Epoch 2/10] [Batch 30/77] [D loss: 0.536483] [G loss: 0.449780]\n",
            "[Epoch 2/10] [Batch 31/77] [D loss: 0.456512] [G loss: 0.612699]\n",
            "[Epoch 2/10] [Batch 32/77] [D loss: 0.448024] [G loss: 0.770968]\n",
            "[Epoch 2/10] [Batch 33/77] [D loss: 0.433860] [G loss: 0.701343]\n",
            "[Epoch 2/10] [Batch 34/77] [D loss: 0.493567] [G loss: 0.609106]\n",
            "[Epoch 2/10] [Batch 35/77] [D loss: 0.476085] [G loss: 0.602838]\n",
            "[Epoch 2/10] [Batch 36/77] [D loss: 0.480494] [G loss: 0.855460]\n",
            "[Epoch 2/10] [Batch 37/77] [D loss: 0.563178] [G loss: 0.541745]\n",
            "[Epoch 2/10] [Batch 38/77] [D loss: 0.487422] [G loss: 0.705852]\n",
            "[Epoch 2/10] [Batch 39/77] [D loss: 0.446715] [G loss: 0.724224]\n",
            "[Epoch 2/10] [Batch 40/77] [D loss: 0.483492] [G loss: 0.932607]\n",
            "[Epoch 2/10] [Batch 41/77] [D loss: 0.404762] [G loss: 0.659828]\n",
            "[Epoch 2/10] [Batch 42/77] [D loss: 0.447439] [G loss: 1.272137]\n",
            "[Epoch 2/10] [Batch 43/77] [D loss: 0.416999] [G loss: 0.698320]\n",
            "[Epoch 2/10] [Batch 44/77] [D loss: 0.379030] [G loss: 1.000944]\n",
            "[Epoch 2/10] [Batch 45/77] [D loss: 0.482225] [G loss: 0.676944]\n",
            "[Epoch 2/10] [Batch 46/77] [D loss: 0.555300] [G loss: 0.918895]\n",
            "[Epoch 2/10] [Batch 47/77] [D loss: 0.777939] [G loss: 0.399116]\n",
            "[Epoch 2/10] [Batch 48/77] [D loss: 0.834138] [G loss: 1.566542]\n",
            "[Epoch 2/10] [Batch 49/77] [D loss: 1.565709] [G loss: 0.104624]\n",
            "[Epoch 2/10] [Batch 50/77] [D loss: 0.626349] [G loss: 0.450926]\n",
            "[Epoch 2/10] [Batch 51/77] [D loss: 0.692661] [G loss: 1.355168]\n",
            "[Epoch 2/10] [Batch 52/77] [D loss: 0.653613] [G loss: 0.396136]\n",
            "[Epoch 2/10] [Batch 53/77] [D loss: 0.554965] [G loss: 0.542697]\n",
            "[Epoch 2/10] [Batch 54/77] [D loss: 0.969629] [G loss: 1.108312]\n",
            "[Epoch 2/10] [Batch 55/77] [D loss: 0.908107] [G loss: 0.232561]\n",
            "[Epoch 2/10] [Batch 56/77] [D loss: 0.628282] [G loss: 0.462639]\n",
            "[Epoch 2/10] [Batch 57/77] [D loss: 0.542578] [G loss: 1.331720]\n",
            "[Epoch 2/10] [Batch 58/77] [D loss: 0.432285] [G loss: 0.617081]\n",
            "[Epoch 2/10] [Batch 59/77] [D loss: 0.462710] [G loss: 0.588926]\n",
            "[Epoch 2/10] [Batch 60/77] [D loss: 0.450287] [G loss: 1.071840]\n",
            "[Epoch 2/10] [Batch 61/77] [D loss: 0.511103] [G loss: 0.782591]\n",
            "[Epoch 2/10] [Batch 62/77] [D loss: 0.668843] [G loss: 0.451558]\n",
            "[Epoch 2/10] [Batch 63/77] [D loss: 0.952169] [G loss: 1.809898]\n",
            "[Epoch 2/10] [Batch 64/77] [D loss: 1.272235] [G loss: 0.143552]\n",
            "[Epoch 2/10] [Batch 65/77] [D loss: 0.460847] [G loss: 0.634836]\n",
            "[Epoch 2/10] [Batch 66/77] [D loss: 0.694700] [G loss: 1.222909]\n",
            "[Epoch 2/10] [Batch 67/77] [D loss: 0.476674] [G loss: 0.536325]\n",
            "[Epoch 2/10] [Batch 68/77] [D loss: 0.458904] [G loss: 0.553408]\n",
            "[Epoch 2/10] [Batch 69/77] [D loss: 0.416957] [G loss: 0.838658]\n",
            "[Epoch 2/10] [Batch 70/77] [D loss: 0.367042] [G loss: 0.858171]\n",
            "[Epoch 2/10] [Batch 71/77] [D loss: 0.407032] [G loss: 0.850346]\n",
            "[Epoch 2/10] [Batch 72/77] [D loss: 0.416766] [G loss: 0.791023]\n",
            "[Epoch 2/10] [Batch 73/77] [D loss: 0.389217] [G loss: 0.826835]\n",
            "[Epoch 2/10] [Batch 74/77] [D loss: 0.621967] [G loss: 0.987138]\n",
            "[Epoch 2/10] [Batch 75/77] [D loss: 1.024527] [G loss: 0.352914]\n",
            "[Epoch 2/10] [Batch 76/77] [D loss: 0.898156] [G loss: 0.971702]\n",
            "[Epoch 3/10] [Batch 0/77] [D loss: 0.571347] [G loss: 0.573800]\n",
            "[Epoch 3/10] [Batch 1/77] [D loss: 0.519641] [G loss: 1.376112]\n",
            "[Epoch 3/10] [Batch 2/77] [D loss: 0.907066] [G loss: 0.423785]\n",
            "[Epoch 3/10] [Batch 3/77] [D loss: 0.379388] [G loss: 1.255546]\n",
            "[Epoch 3/10] [Batch 4/77] [D loss: 0.511388] [G loss: 1.362211]\n",
            "[Epoch 3/10] [Batch 5/77] [D loss: 0.768678] [G loss: 0.344149]\n",
            "[Epoch 3/10] [Batch 6/77] [D loss: 0.580908] [G loss: 0.628200]\n",
            "[Epoch 3/10] [Batch 7/77] [D loss: 0.511540] [G loss: 0.790299]\n",
            "[Epoch 3/10] [Batch 8/77] [D loss: 0.521039] [G loss: 0.762456]\n",
            "[Epoch 3/10] [Batch 9/77] [D loss: 0.536869] [G loss: 0.898357]\n",
            "[Epoch 3/10] [Batch 10/77] [D loss: 0.821655] [G loss: 0.266626]\n",
            "[Epoch 3/10] [Batch 11/77] [D loss: 1.217748] [G loss: 2.181813]\n",
            "[Epoch 3/10] [Batch 12/77] [D loss: 1.008982] [G loss: 0.183324]\n",
            "[Epoch 3/10] [Batch 13/77] [D loss: 0.500599] [G loss: 0.539881]\n",
            "[Epoch 3/10] [Batch 14/77] [D loss: 0.548480] [G loss: 1.096025]\n",
            "[Epoch 3/10] [Batch 15/77] [D loss: 0.529038] [G loss: 0.509031]\n",
            "[Epoch 3/10] [Batch 16/77] [D loss: 0.411746] [G loss: 0.865195]\n",
            "[Epoch 3/10] [Batch 17/77] [D loss: 0.378784] [G loss: 1.197097]\n",
            "[Epoch 3/10] [Batch 18/77] [D loss: 0.471961] [G loss: 0.591028]\n",
            "[Epoch 3/10] [Batch 19/77] [D loss: 0.469546] [G loss: 1.052556]\n",
            "[Epoch 3/10] [Batch 20/77] [D loss: 0.563053] [G loss: 0.548194]\n",
            "[Epoch 3/10] [Batch 21/77] [D loss: 0.649239] [G loss: 0.558057]\n",
            "[Epoch 3/10] [Batch 22/77] [D loss: 0.617738] [G loss: 0.855693]\n",
            "[Epoch 3/10] [Batch 23/77] [D loss: 0.754593] [G loss: 0.616186]\n",
            "[Epoch 3/10] [Batch 24/77] [D loss: 0.604373] [G loss: 1.564043]\n",
            "[Epoch 3/10] [Batch 25/77] [D loss: 0.963061] [G loss: 0.221099]\n",
            "[Epoch 3/10] [Batch 26/77] [D loss: 0.526848] [G loss: 0.799233]\n",
            "[Epoch 3/10] [Batch 27/77] [D loss: 0.536771] [G loss: 0.712109]\n",
            "[Epoch 3/10] [Batch 28/77] [D loss: 0.672294] [G loss: 0.368987]\n",
            "[Epoch 3/10] [Batch 29/77] [D loss: 0.677697] [G loss: 0.857061]\n",
            "[Epoch 3/10] [Batch 30/77] [D loss: 0.619686] [G loss: 0.401336]\n",
            "[Epoch 3/10] [Batch 31/77] [D loss: 0.435780] [G loss: 0.740685]\n",
            "[Epoch 3/10] [Batch 32/77] [D loss: 0.490254] [G loss: 1.122032]\n",
            "[Epoch 3/10] [Batch 33/77] [D loss: 0.515085] [G loss: 0.555166]\n",
            "[Epoch 3/10] [Batch 34/77] [D loss: 0.347085] [G loss: 1.042371]\n",
            "[Epoch 3/10] [Batch 35/77] [D loss: 0.570155] [G loss: 1.379356]\n",
            "[Epoch 3/10] [Batch 36/77] [D loss: 1.137712] [G loss: 0.258977]\n",
            "[Epoch 3/10] [Batch 37/77] [D loss: 0.831847] [G loss: 0.507092]\n",
            "[Epoch 3/10] [Batch 38/77] [D loss: 0.621244] [G loss: 0.963933]\n",
            "[Epoch 3/10] [Batch 39/77] [D loss: 0.507353] [G loss: 0.629094]\n",
            "[Epoch 3/10] [Batch 40/77] [D loss: 0.434271] [G loss: 0.869640]\n",
            "[Epoch 3/10] [Batch 41/77] [D loss: 0.325210] [G loss: 1.239491]\n",
            "[Epoch 3/10] [Batch 42/77] [D loss: 0.441283] [G loss: 0.900322]\n",
            "[Epoch 3/10] [Batch 43/77] [D loss: 0.611912] [G loss: 1.393376]\n",
            "[Epoch 3/10] [Batch 44/77] [D loss: 0.504916] [G loss: 0.532470]\n",
            "[Epoch 3/10] [Batch 45/77] [D loss: 0.453649] [G loss: 0.688030]\n",
            "[Epoch 3/10] [Batch 46/77] [D loss: 0.528367] [G loss: 0.937991]\n",
            "[Epoch 3/10] [Batch 47/77] [D loss: 0.424657] [G loss: 0.689030]\n",
            "[Epoch 3/10] [Batch 48/77] [D loss: 0.426258] [G loss: 0.649177]\n",
            "[Epoch 3/10] [Batch 49/77] [D loss: 0.424774] [G loss: 0.784055]\n",
            "[Epoch 3/10] [Batch 50/77] [D loss: 0.359510] [G loss: 1.018578]\n",
            "[Epoch 3/10] [Batch 51/77] [D loss: 0.401974] [G loss: 0.791118]\n",
            "[Epoch 3/10] [Batch 52/77] [D loss: 0.382125] [G loss: 0.895318]\n",
            "[Epoch 3/10] [Batch 53/77] [D loss: 0.510009] [G loss: 1.070740]\n",
            "[Epoch 3/10] [Batch 54/77] [D loss: 0.746691] [G loss: 0.357288]\n",
            "[Epoch 3/10] [Batch 55/77] [D loss: 1.066346] [G loss: 1.744285]\n",
            "[Epoch 3/10] [Batch 56/77] [D loss: 1.180639] [G loss: 0.148690]\n",
            "[Epoch 3/10] [Batch 57/77] [D loss: 0.590655] [G loss: 0.466848]\n",
            "[Epoch 3/10] [Batch 58/77] [D loss: 0.717830] [G loss: 1.460618]\n",
            "[Epoch 3/10] [Batch 59/77] [D loss: 0.568322] [G loss: 0.630698]\n",
            "[Epoch 3/10] [Batch 60/77] [D loss: 0.532813] [G loss: 0.524714]\n",
            "[Epoch 3/10] [Batch 61/77] [D loss: 0.443026] [G loss: 0.993694]\n",
            "[Epoch 3/10] [Batch 62/77] [D loss: 0.392616] [G loss: 0.926582]\n",
            "[Epoch 3/10] [Batch 63/77] [D loss: 0.400817] [G loss: 0.895140]\n",
            "[Epoch 3/10] [Batch 64/77] [D loss: 0.418710] [G loss: 1.183487]\n",
            "[Epoch 3/10] [Batch 65/77] [D loss: 0.700561] [G loss: 0.415502]\n",
            "[Epoch 3/10] [Batch 66/77] [D loss: 0.794410] [G loss: 1.267917]\n",
            "[Epoch 3/10] [Batch 67/77] [D loss: 1.208631] [G loss: 0.203124]\n",
            "[Epoch 3/10] [Batch 68/77] [D loss: 0.606212] [G loss: 0.815105]\n",
            "[Epoch 3/10] [Batch 69/77] [D loss: 0.555778] [G loss: 1.376900]\n",
            "[Epoch 3/10] [Batch 70/77] [D loss: 0.450483] [G loss: 0.714368]\n",
            "[Epoch 3/10] [Batch 71/77] [D loss: 0.399197] [G loss: 0.879449]\n",
            "[Epoch 3/10] [Batch 72/77] [D loss: 0.383002] [G loss: 1.010528]\n",
            "[Epoch 3/10] [Batch 73/77] [D loss: 0.371019] [G loss: 0.864725]\n",
            "[Epoch 3/10] [Batch 74/77] [D loss: 0.416857] [G loss: 1.110073]\n",
            "[Epoch 3/10] [Batch 75/77] [D loss: 0.537820] [G loss: 0.741044]\n",
            "[Epoch 3/10] [Batch 76/77] [D loss: 0.585912] [G loss: 0.490750]\n",
            "[Epoch 4/10] [Batch 0/77] [D loss: 0.713979] [G loss: 0.782108]\n",
            "[Epoch 4/10] [Batch 1/77] [D loss: 0.794581] [G loss: 0.304798]\n",
            "[Epoch 4/10] [Batch 2/77] [D loss: 0.551788] [G loss: 1.423072]\n",
            "[Epoch 4/10] [Batch 3/77] [D loss: 0.514854] [G loss: 0.733126]\n",
            "[Epoch 4/10] [Batch 4/77] [D loss: 0.440880] [G loss: 0.801699]\n",
            "[Epoch 4/10] [Batch 5/77] [D loss: 0.296064] [G loss: 1.147811]\n",
            "[Epoch 4/10] [Batch 6/77] [D loss: 0.272005] [G loss: 1.471999]\n",
            "[Epoch 4/10] [Batch 7/77] [D loss: 0.470937] [G loss: 0.700954]\n",
            "[Epoch 4/10] [Batch 8/77] [D loss: 0.557545] [G loss: 1.109856]\n",
            "[Epoch 4/10] [Batch 9/77] [D loss: 1.114540] [G loss: 0.181344]\n",
            "[Epoch 4/10] [Batch 10/77] [D loss: 0.488477] [G loss: 0.704973]\n",
            "[Epoch 4/10] [Batch 11/77] [D loss: 0.686160] [G loss: 1.330562]\n",
            "[Epoch 4/10] [Batch 12/77] [D loss: 0.543087] [G loss: 0.464095]\n",
            "[Epoch 4/10] [Batch 13/77] [D loss: 0.461660] [G loss: 0.724217]\n",
            "[Epoch 4/10] [Batch 14/77] [D loss: 0.347023] [G loss: 1.559023]\n",
            "[Epoch 4/10] [Batch 15/77] [D loss: 0.336222] [G loss: 1.092887]\n",
            "[Epoch 4/10] [Batch 16/77] [D loss: 0.447763] [G loss: 0.822193]\n",
            "[Epoch 4/10] [Batch 17/77] [D loss: 0.447585] [G loss: 0.622518]\n",
            "[Epoch 4/10] [Batch 18/77] [D loss: 0.530906] [G loss: 1.165525]\n",
            "[Epoch 4/10] [Batch 19/77] [D loss: 0.691284] [G loss: 0.400157]\n",
            "[Epoch 4/10] [Batch 20/77] [D loss: 0.502046] [G loss: 1.141666]\n",
            "[Epoch 4/10] [Batch 21/77] [D loss: 0.466721] [G loss: 0.614100]\n",
            "[Epoch 4/10] [Batch 22/77] [D loss: 0.513331] [G loss: 0.798987]\n",
            "[Epoch 4/10] [Batch 23/77] [D loss: 0.572353] [G loss: 0.585200]\n",
            "[Epoch 4/10] [Batch 24/77] [D loss: 0.624364] [G loss: 0.580946]\n",
            "[Epoch 4/10] [Batch 25/77] [D loss: 0.493100] [G loss: 0.937779]\n",
            "[Epoch 4/10] [Batch 26/77] [D loss: 0.493629] [G loss: 0.688102]\n",
            "[Epoch 4/10] [Batch 27/77] [D loss: 0.473042] [G loss: 0.988880]\n",
            "[Epoch 4/10] [Batch 28/77] [D loss: 0.415572] [G loss: 0.879662]\n",
            "[Epoch 4/10] [Batch 29/77] [D loss: 0.661907] [G loss: 1.527200]\n",
            "[Epoch 4/10] [Batch 30/77] [D loss: 1.811221] [G loss: 0.078681]\n",
            "[Epoch 4/10] [Batch 31/77] [D loss: 1.132654] [G loss: 3.865380]\n",
            "[Epoch 4/10] [Batch 32/77] [D loss: 1.113192] [G loss: 0.183986]\n",
            "[Epoch 4/10] [Batch 33/77] [D loss: 0.602543] [G loss: 0.415379]\n",
            "[Epoch 4/10] [Batch 34/77] [D loss: 0.870191] [G loss: 1.980718]\n",
            "[Epoch 4/10] [Batch 35/77] [D loss: 0.740260] [G loss: 0.328606]\n",
            "[Epoch 4/10] [Batch 36/77] [D loss: 0.494319] [G loss: 0.522739]\n",
            "[Epoch 4/10] [Batch 37/77] [D loss: 0.397633] [G loss: 1.231238]\n",
            "[Epoch 4/10] [Batch 38/77] [D loss: 0.346666] [G loss: 0.833410]\n",
            "[Epoch 4/10] [Batch 39/77] [D loss: 0.374117] [G loss: 0.861620]\n",
            "[Epoch 4/10] [Batch 40/77] [D loss: 0.357409] [G loss: 0.923119]\n",
            "[Epoch 4/10] [Batch 41/77] [D loss: 0.362040] [G loss: 0.942222]\n",
            "[Epoch 4/10] [Batch 42/77] [D loss: 0.462030] [G loss: 0.752113]\n",
            "[Epoch 4/10] [Batch 43/77] [D loss: 0.623601] [G loss: 0.453293]\n",
            "[Epoch 4/10] [Batch 44/77] [D loss: 0.990801] [G loss: 1.972469]\n",
            "[Epoch 4/10] [Batch 45/77] [D loss: 1.466576] [G loss: 0.096885]\n",
            "[Epoch 4/10] [Batch 46/77] [D loss: 0.618437] [G loss: 0.390888]\n",
            "[Epoch 4/10] [Batch 47/77] [D loss: 0.472033] [G loss: 1.172787]\n",
            "[Epoch 4/10] [Batch 48/77] [D loss: 0.390671] [G loss: 1.046476]\n",
            "[Epoch 4/10] [Batch 49/77] [D loss: 0.417546] [G loss: 0.692454]\n",
            "[Epoch 4/10] [Batch 50/77] [D loss: 0.388946] [G loss: 0.771479]\n",
            "[Epoch 4/10] [Batch 51/77] [D loss: 0.850672] [G loss: 1.179651]\n",
            "[Epoch 4/10] [Batch 52/77] [D loss: 1.352259] [G loss: 0.138582]\n",
            "[Epoch 4/10] [Batch 53/77] [D loss: 0.518949] [G loss: 0.528666]\n",
            "[Epoch 4/10] [Batch 54/77] [D loss: 0.825933] [G loss: 1.658540]\n",
            "[Epoch 4/10] [Batch 55/77] [D loss: 0.462202] [G loss: 0.573255]\n",
            "[Epoch 4/10] [Batch 56/77] [D loss: 0.374282] [G loss: 0.755134]\n",
            "[Epoch 4/10] [Batch 57/77] [D loss: 0.466040] [G loss: 1.321256]\n",
            "[Epoch 4/10] [Batch 58/77] [D loss: 0.593072] [G loss: 0.506902]\n",
            "[Epoch 4/10] [Batch 59/77] [D loss: 0.498055] [G loss: 0.677999]\n",
            "[Epoch 4/10] [Batch 60/77] [D loss: 0.505339] [G loss: 1.552376]\n",
            "[Epoch 4/10] [Batch 61/77] [D loss: 0.800694] [G loss: 0.496268]\n",
            "[Epoch 4/10] [Batch 62/77] [D loss: 0.508752] [G loss: 0.987620]\n",
            "[Epoch 4/10] [Batch 63/77] [D loss: 0.479388] [G loss: 0.835634]\n",
            "[Epoch 4/10] [Batch 64/77] [D loss: 0.514242] [G loss: 0.538567]\n",
            "[Epoch 4/10] [Batch 65/77] [D loss: 0.585011] [G loss: 1.008313]\n",
            "[Epoch 4/10] [Batch 66/77] [D loss: 0.555951] [G loss: 0.475955]\n",
            "[Epoch 4/10] [Batch 67/77] [D loss: 0.373751] [G loss: 1.089882]\n",
            "[Epoch 4/10] [Batch 68/77] [D loss: 0.343414] [G loss: 0.974986]\n",
            "[Epoch 4/10] [Batch 69/77] [D loss: 0.380302] [G loss: 0.817918]\n",
            "[Epoch 4/10] [Batch 70/77] [D loss: 0.418698] [G loss: 1.096088]\n",
            "[Epoch 4/10] [Batch 71/77] [D loss: 0.484318] [G loss: 0.515471]\n",
            "[Epoch 4/10] [Batch 72/77] [D loss: 0.307605] [G loss: 1.148543]\n",
            "[Epoch 4/10] [Batch 73/77] [D loss: 0.284510] [G loss: 1.319533]\n",
            "[Epoch 4/10] [Batch 74/77] [D loss: 0.428338] [G loss: 0.751286]\n",
            "[Epoch 4/10] [Batch 75/77] [D loss: 0.670615] [G loss: 1.652657]\n",
            "[Epoch 4/10] [Batch 76/77] [D loss: 1.968084] [G loss: 0.099625]\n",
            "[Epoch 5/10] [Batch 0/77] [D loss: 0.677321] [G loss: 0.377073]\n",
            "[Epoch 5/10] [Batch 1/77] [D loss: 1.033157] [G loss: 2.247322]\n",
            "[Epoch 5/10] [Batch 2/77] [D loss: 0.540556] [G loss: 0.465701]\n",
            "[Epoch 5/10] [Batch 3/77] [D loss: 0.316037] [G loss: 0.840911]\n",
            "[Epoch 5/10] [Batch 4/77] [D loss: 0.396323] [G loss: 1.692601]\n",
            "[Epoch 5/10] [Batch 5/77] [D loss: 0.591083] [G loss: 0.402064]\n",
            "[Epoch 5/10] [Batch 6/77] [D loss: 0.492907] [G loss: 0.633757]\n",
            "[Epoch 5/10] [Batch 7/77] [D loss: 0.473248] [G loss: 0.858118]\n",
            "[Epoch 5/10] [Batch 8/77] [D loss: 0.739949] [G loss: 0.574569]\n",
            "[Epoch 5/10] [Batch 9/77] [D loss: 0.818591] [G loss: 0.335868]\n",
            "[Epoch 5/10] [Batch 10/77] [D loss: 0.457306] [G loss: 0.870069]\n",
            "[Epoch 5/10] [Batch 11/77] [D loss: 0.695949] [G loss: 1.390129]\n",
            "[Epoch 5/10] [Batch 12/77] [D loss: 0.877619] [G loss: 0.370101]\n",
            "[Epoch 5/10] [Batch 13/77] [D loss: 0.626265] [G loss: 0.486229]\n",
            "[Epoch 5/10] [Batch 14/77] [D loss: 0.588798] [G loss: 1.767433]\n",
            "[Epoch 5/10] [Batch 15/77] [D loss: 0.674531] [G loss: 0.387345]\n",
            "[Epoch 5/10] [Batch 16/77] [D loss: 0.578964] [G loss: 0.536019]\n",
            "[Epoch 5/10] [Batch 17/77] [D loss: 0.503063] [G loss: 1.222970]\n",
            "[Epoch 5/10] [Batch 18/77] [D loss: 0.429900] [G loss: 0.661014]\n",
            "[Epoch 5/10] [Batch 19/77] [D loss: 0.414095] [G loss: 0.763240]\n",
            "[Epoch 5/10] [Batch 20/77] [D loss: 0.404084] [G loss: 1.337315]\n",
            "[Epoch 5/10] [Batch 21/77] [D loss: 0.349690] [G loss: 0.853751]\n",
            "[Epoch 5/10] [Batch 22/77] [D loss: 0.337873] [G loss: 1.054924]\n",
            "[Epoch 5/10] [Batch 23/77] [D loss: 0.365754] [G loss: 1.122959]\n",
            "[Epoch 5/10] [Batch 24/77] [D loss: 0.348826] [G loss: 0.882006]\n",
            "[Epoch 5/10] [Batch 25/77] [D loss: 0.443341] [G loss: 1.063371]\n",
            "[Epoch 5/10] [Batch 26/77] [D loss: 0.563118] [G loss: 0.769279]\n",
            "[Epoch 5/10] [Batch 27/77] [D loss: 0.646659] [G loss: 1.249942]\n",
            "[Epoch 5/10] [Batch 28/77] [D loss: 0.782396] [G loss: 0.525068]\n",
            "[Epoch 5/10] [Batch 29/77] [D loss: 0.682492] [G loss: 1.733582]\n",
            "[Epoch 5/10] [Batch 30/77] [D loss: 1.036216] [G loss: 0.715667]\n",
            "[Epoch 5/10] [Batch 31/77] [D loss: 0.780785] [G loss: 1.016534]\n",
            "[Epoch 5/10] [Batch 32/77] [D loss: 1.104104] [G loss: 0.193775]\n",
            "[Epoch 5/10] [Batch 33/77] [D loss: 0.583665] [G loss: 1.077435]\n",
            "[Epoch 5/10] [Batch 34/77] [D loss: 0.767873] [G loss: 0.503379]\n",
            "[Epoch 5/10] [Batch 35/77] [D loss: 0.464074] [G loss: 1.103736]\n",
            "[Epoch 5/10] [Batch 36/77] [D loss: 0.559702] [G loss: 0.720809]\n",
            "[Epoch 5/10] [Batch 37/77] [D loss: 0.551438] [G loss: 0.887457]\n",
            "[Epoch 5/10] [Batch 38/77] [D loss: 0.546126] [G loss: 0.493784]\n",
            "[Epoch 5/10] [Batch 39/77] [D loss: 0.606876] [G loss: 1.451017]\n",
            "[Epoch 5/10] [Batch 40/77] [D loss: 1.039441] [G loss: 0.239353]\n",
            "[Epoch 5/10] [Batch 41/77] [D loss: 0.436032] [G loss: 0.679178]\n",
            "[Epoch 5/10] [Batch 42/77] [D loss: 0.886734] [G loss: 1.309892]\n",
            "[Epoch 5/10] [Batch 43/77] [D loss: 0.820178] [G loss: 0.284552]\n",
            "[Epoch 5/10] [Batch 44/77] [D loss: 0.734088] [G loss: 0.334924]\n",
            "[Epoch 5/10] [Batch 45/77] [D loss: 0.450149] [G loss: 0.847869]\n",
            "[Epoch 5/10] [Batch 46/77] [D loss: 0.473051] [G loss: 1.175406]\n",
            "[Epoch 5/10] [Batch 47/77] [D loss: 0.483135] [G loss: 0.651144]\n",
            "[Epoch 5/10] [Batch 48/77] [D loss: 0.437517] [G loss: 0.681993]\n",
            "[Epoch 5/10] [Batch 49/77] [D loss: 0.410231] [G loss: 0.827279]\n",
            "[Epoch 5/10] [Batch 50/77] [D loss: 0.352934] [G loss: 0.980454]\n",
            "[Epoch 5/10] [Batch 51/77] [D loss: 0.434202] [G loss: 0.969324]\n",
            "[Epoch 5/10] [Batch 52/77] [D loss: 0.410204] [G loss: 0.837183]\n",
            "[Epoch 5/10] [Batch 53/77] [D loss: 0.503303] [G loss: 0.726373]\n",
            "[Epoch 5/10] [Batch 54/77] [D loss: 0.464910] [G loss: 0.772079]\n",
            "[Epoch 5/10] [Batch 55/77] [D loss: 0.438587] [G loss: 0.759674]\n",
            "[Epoch 5/10] [Batch 56/77] [D loss: 0.503447] [G loss: 1.332140]\n",
            "[Epoch 5/10] [Batch 57/77] [D loss: 1.111552] [G loss: 0.209186]\n",
            "[Epoch 5/10] [Batch 58/77] [D loss: 0.889580] [G loss: 1.799531]\n",
            "[Epoch 5/10] [Batch 59/77] [D loss: 0.535340] [G loss: 0.665750]\n",
            "[Epoch 5/10] [Batch 60/77] [D loss: 0.514326] [G loss: 0.655530]\n",
            "[Epoch 5/10] [Batch 61/77] [D loss: 0.612876] [G loss: 1.140085]\n",
            "[Epoch 5/10] [Batch 62/77] [D loss: 0.689177] [G loss: 0.427992]\n",
            "[Epoch 5/10] [Batch 63/77] [D loss: 0.534750] [G loss: 0.800480]\n",
            "[Epoch 5/10] [Batch 64/77] [D loss: 0.473985] [G loss: 0.952937]\n",
            "[Epoch 5/10] [Batch 65/77] [D loss: 0.435350] [G loss: 0.693523]\n",
            "[Epoch 5/10] [Batch 66/77] [D loss: 0.466320] [G loss: 1.541520]\n",
            "[Epoch 5/10] [Batch 67/77] [D loss: 0.640631] [G loss: 0.518699]\n",
            "[Epoch 5/10] [Batch 68/77] [D loss: 0.402487] [G loss: 1.607368]\n",
            "[Epoch 5/10] [Batch 69/77] [D loss: 0.590986] [G loss: 0.869281]\n",
            "[Epoch 5/10] [Batch 70/77] [D loss: 0.553074] [G loss: 0.600486]\n",
            "[Epoch 5/10] [Batch 71/77] [D loss: 0.675663] [G loss: 1.304566]\n",
            "[Epoch 5/10] [Batch 72/77] [D loss: 0.832983] [G loss: 0.468758]\n",
            "[Epoch 5/10] [Batch 73/77] [D loss: 0.545062] [G loss: 0.702969]\n",
            "[Epoch 5/10] [Batch 74/77] [D loss: 0.722543] [G loss: 1.317474]\n",
            "[Epoch 5/10] [Batch 75/77] [D loss: 0.759332] [G loss: 0.703525]\n",
            "[Epoch 5/10] [Batch 76/77] [D loss: 0.409165] [G loss: 0.744492]\n",
            "[Epoch 6/10] [Batch 0/77] [D loss: 0.449417] [G loss: 0.768387]\n",
            "[Epoch 6/10] [Batch 1/77] [D loss: 0.653175] [G loss: 1.500048]\n",
            "[Epoch 6/10] [Batch 2/77] [D loss: 0.622153] [G loss: 0.461590]\n",
            "[Epoch 6/10] [Batch 3/77] [D loss: 0.463655] [G loss: 0.621806]\n",
            "[Epoch 6/10] [Batch 4/77] [D loss: 0.637739] [G loss: 1.857297]\n",
            "[Epoch 6/10] [Batch 5/77] [D loss: 0.473047] [G loss: 0.631838]\n",
            "[Epoch 6/10] [Batch 6/77] [D loss: 0.496567] [G loss: 0.566887]\n",
            "[Epoch 6/10] [Batch 7/77] [D loss: 0.525736] [G loss: 1.234347]\n",
            "[Epoch 6/10] [Batch 8/77] [D loss: 0.467789] [G loss: 0.731321]\n",
            "[Epoch 6/10] [Batch 9/77] [D loss: 0.483082] [G loss: 1.199975]\n",
            "[Epoch 6/10] [Batch 10/77] [D loss: 0.697390] [G loss: 0.738144]\n",
            "[Epoch 6/10] [Batch 11/77] [D loss: 0.440511] [G loss: 1.287070]\n",
            "[Epoch 6/10] [Batch 12/77] [D loss: 0.517204] [G loss: 0.732408]\n",
            "[Epoch 6/10] [Batch 13/77] [D loss: 0.426116] [G loss: 1.090211]\n",
            "[Epoch 6/10] [Batch 14/77] [D loss: 0.535411] [G loss: 0.985284]\n",
            "[Epoch 6/10] [Batch 15/77] [D loss: 0.550271] [G loss: 0.668149]\n",
            "[Epoch 6/10] [Batch 16/77] [D loss: 0.633477] [G loss: 1.654333]\n",
            "[Epoch 6/10] [Batch 17/77] [D loss: 0.711199] [G loss: 0.494185]\n",
            "[Epoch 6/10] [Batch 18/77] [D loss: 0.751334] [G loss: 1.373124]\n",
            "[Epoch 6/10] [Batch 19/77] [D loss: 0.983092] [G loss: 0.269891]\n",
            "[Epoch 6/10] [Batch 20/77] [D loss: 0.605484] [G loss: 1.027369]\n",
            "[Epoch 6/10] [Batch 21/77] [D loss: 0.535802] [G loss: 0.670305]\n",
            "[Epoch 6/10] [Batch 22/77] [D loss: 0.489314] [G loss: 0.636308]\n",
            "[Epoch 6/10] [Batch 23/77] [D loss: 0.440552] [G loss: 0.741218]\n",
            "[Epoch 6/10] [Batch 24/77] [D loss: 0.557555] [G loss: 1.139158]\n",
            "[Epoch 6/10] [Batch 25/77] [D loss: 0.488294] [G loss: 0.627466]\n",
            "[Epoch 6/10] [Batch 26/77] [D loss: 0.403726] [G loss: 0.934003]\n",
            "[Epoch 6/10] [Batch 27/77] [D loss: 0.570401] [G loss: 1.265808]\n",
            "[Epoch 6/10] [Batch 28/77] [D loss: 0.569624] [G loss: 0.537019]\n",
            "[Epoch 6/10] [Batch 29/77] [D loss: 0.463914] [G loss: 0.916260]\n",
            "[Epoch 6/10] [Batch 30/77] [D loss: 0.520946] [G loss: 1.366029]\n",
            "[Epoch 6/10] [Batch 31/77] [D loss: 0.578566] [G loss: 0.463640]\n",
            "[Epoch 6/10] [Batch 32/77] [D loss: 0.544603] [G loss: 1.880145]\n",
            "[Epoch 6/10] [Batch 33/77] [D loss: 1.145135] [G loss: 0.182455]\n",
            "[Epoch 6/10] [Batch 34/77] [D loss: 0.631921] [G loss: 2.111014]\n",
            "[Epoch 6/10] [Batch 35/77] [D loss: 0.593997] [G loss: 0.789517]\n",
            "[Epoch 6/10] [Batch 36/77] [D loss: 0.581017] [G loss: 0.702316]\n",
            "[Epoch 6/10] [Batch 37/77] [D loss: 0.553162] [G loss: 1.246470]\n",
            "[Epoch 6/10] [Batch 38/77] [D loss: 0.504019] [G loss: 0.784270]\n",
            "[Epoch 6/10] [Batch 39/77] [D loss: 0.424113] [G loss: 0.718019]\n",
            "[Epoch 6/10] [Batch 40/77] [D loss: 0.621265] [G loss: 1.567409]\n",
            "[Epoch 6/10] [Batch 41/77] [D loss: 0.511865] [G loss: 0.729205]\n",
            "[Epoch 6/10] [Batch 42/77] [D loss: 0.615437] [G loss: 0.711286]\n",
            "[Epoch 6/10] [Batch 43/77] [D loss: 0.527791] [G loss: 0.866657]\n",
            "[Epoch 6/10] [Batch 44/77] [D loss: 0.541522] [G loss: 0.741136]\n",
            "[Epoch 6/10] [Batch 45/77] [D loss: 0.586762] [G loss: 0.688258]\n",
            "[Epoch 6/10] [Batch 46/77] [D loss: 0.669721] [G loss: 0.966477]\n",
            "[Epoch 6/10] [Batch 47/77] [D loss: 0.954595] [G loss: 0.379886]\n",
            "[Epoch 6/10] [Batch 48/77] [D loss: 0.598970] [G loss: 1.757074]\n",
            "[Epoch 6/10] [Batch 49/77] [D loss: 0.607978] [G loss: 0.592392]\n",
            "[Epoch 6/10] [Batch 50/77] [D loss: 0.444963] [G loss: 0.965337]\n",
            "[Epoch 6/10] [Batch 51/77] [D loss: 0.522576] [G loss: 1.394381]\n",
            "[Epoch 6/10] [Batch 52/77] [D loss: 0.597482] [G loss: 0.435705]\n",
            "[Epoch 6/10] [Batch 53/77] [D loss: 0.687233] [G loss: 1.609213]\n",
            "[Epoch 6/10] [Batch 54/77] [D loss: 0.837875] [G loss: 0.249141]\n",
            "[Epoch 6/10] [Batch 55/77] [D loss: 0.561192] [G loss: 0.737748]\n",
            "[Epoch 6/10] [Batch 56/77] [D loss: 0.557428] [G loss: 1.121182]\n",
            "[Epoch 6/10] [Batch 57/77] [D loss: 0.541321] [G loss: 0.663753]\n",
            "[Epoch 6/10] [Batch 58/77] [D loss: 0.511570] [G loss: 0.617804]\n",
            "[Epoch 6/10] [Batch 59/77] [D loss: 0.503262] [G loss: 0.899852]\n",
            "[Epoch 6/10] [Batch 60/77] [D loss: 0.431401] [G loss: 0.851380]\n",
            "[Epoch 6/10] [Batch 61/77] [D loss: 0.530182] [G loss: 0.831526]\n",
            "[Epoch 6/10] [Batch 62/77] [D loss: 0.524537] [G loss: 0.910031]\n",
            "[Epoch 6/10] [Batch 63/77] [D loss: 0.760131] [G loss: 0.604038]\n",
            "[Epoch 6/10] [Batch 64/77] [D loss: 0.771156] [G loss: 1.890991]\n",
            "[Epoch 6/10] [Batch 65/77] [D loss: 0.664342] [G loss: 0.483145]\n",
            "[Epoch 6/10] [Batch 66/77] [D loss: 0.591971] [G loss: 1.047727]\n",
            "[Epoch 6/10] [Batch 67/77] [D loss: 0.415871] [G loss: 0.925722]\n",
            "[Epoch 6/10] [Batch 68/77] [D loss: 0.560697] [G loss: 0.734972]\n",
            "[Epoch 6/10] [Batch 69/77] [D loss: 0.465210] [G loss: 0.781651]\n",
            "[Epoch 6/10] [Batch 70/77] [D loss: 0.389288] [G loss: 1.189479]\n",
            "[Epoch 6/10] [Batch 71/77] [D loss: 0.414389] [G loss: 0.933714]\n",
            "[Epoch 6/10] [Batch 72/77] [D loss: 0.354843] [G loss: 1.209051]\n",
            "[Epoch 6/10] [Batch 73/77] [D loss: 0.537115] [G loss: 1.076298]\n",
            "[Epoch 6/10] [Batch 74/77] [D loss: 0.982715] [G loss: 0.937135]\n",
            "[Epoch 6/10] [Batch 75/77] [D loss: 0.421255] [G loss: 1.327073]\n",
            "[Epoch 6/10] [Batch 76/77] [D loss: 0.474254] [G loss: 0.859053]\n",
            "[Epoch 7/10] [Batch 0/77] [D loss: 0.396291] [G loss: 1.928245]\n",
            "[Epoch 7/10] [Batch 1/77] [D loss: 0.333757] [G loss: 1.082615]\n",
            "[Epoch 7/10] [Batch 2/77] [D loss: 0.554776] [G loss: 1.908891]\n",
            "[Epoch 7/10] [Batch 3/77] [D loss: 1.888881] [G loss: 0.121130]\n",
            "[Epoch 7/10] [Batch 4/77] [D loss: 0.567701] [G loss: 9.445480]\n",
            "[Epoch 7/10] [Batch 5/77] [D loss: 0.943590] [G loss: 0.264123]\n",
            "[Epoch 7/10] [Batch 6/77] [D loss: 0.536771] [G loss: 0.829258]\n",
            "[Epoch 7/10] [Batch 7/77] [D loss: 0.607879] [G loss: 1.584196]\n",
            "[Epoch 7/10] [Batch 8/77] [D loss: 0.534678] [G loss: 0.571134]\n",
            "[Epoch 7/10] [Batch 9/77] [D loss: 0.513812] [G loss: 0.624505]\n",
            "[Epoch 7/10] [Batch 10/77] [D loss: 0.470165] [G loss: 0.858151]\n",
            "[Epoch 7/10] [Batch 11/77] [D loss: 0.417952] [G loss: 0.940418]\n",
            "[Epoch 7/10] [Batch 12/77] [D loss: 0.441515] [G loss: 0.936309]\n",
            "[Epoch 7/10] [Batch 13/77] [D loss: 0.423989] [G loss: 0.645256]\n",
            "[Epoch 7/10] [Batch 14/77] [D loss: 0.383719] [G loss: 1.289330]\n",
            "[Epoch 7/10] [Batch 15/77] [D loss: 0.348088] [G loss: 1.139817]\n",
            "[Epoch 7/10] [Batch 16/77] [D loss: 0.431355] [G loss: 0.799884]\n",
            "[Epoch 7/10] [Batch 17/77] [D loss: 0.429724] [G loss: 1.228364]\n",
            "[Epoch 7/10] [Batch 18/77] [D loss: 0.345582] [G loss: 0.898765]\n",
            "[Epoch 7/10] [Batch 19/77] [D loss: 0.515093] [G loss: 1.101213]\n",
            "[Epoch 7/10] [Batch 20/77] [D loss: 0.324601] [G loss: 1.072406]\n",
            "[Epoch 7/10] [Batch 21/77] [D loss: 0.385171] [G loss: 1.369275]\n",
            "[Epoch 7/10] [Batch 22/77] [D loss: 0.428406] [G loss: 0.853235]\n",
            "[Epoch 7/10] [Batch 23/77] [D loss: 0.505010] [G loss: 1.237950]\n",
            "[Epoch 7/10] [Batch 24/77] [D loss: 0.465793] [G loss: 0.762594]\n",
            "[Epoch 7/10] [Batch 25/77] [D loss: 0.460406] [G loss: 1.557796]\n",
            "[Epoch 7/10] [Batch 26/77] [D loss: 0.892279] [G loss: 0.392568]\n",
            "[Epoch 7/10] [Batch 27/77] [D loss: 1.193308] [G loss: 2.572980]\n",
            "[Epoch 7/10] [Batch 28/77] [D loss: 0.841685] [G loss: 0.290044]\n",
            "[Epoch 7/10] [Batch 29/77] [D loss: 0.361169] [G loss: 0.909669]\n",
            "[Epoch 7/10] [Batch 30/77] [D loss: 0.543928] [G loss: 1.780913]\n",
            "[Epoch 7/10] [Batch 31/77] [D loss: 0.425494] [G loss: 0.661716]\n",
            "[Epoch 7/10] [Batch 32/77] [D loss: 0.344566] [G loss: 0.949136]\n",
            "[Epoch 7/10] [Batch 33/77] [D loss: 0.488561] [G loss: 1.421696]\n",
            "[Epoch 7/10] [Batch 34/77] [D loss: 0.470328] [G loss: 0.648192]\n",
            "[Epoch 7/10] [Batch 35/77] [D loss: 0.419516] [G loss: 0.926077]\n",
            "[Epoch 7/10] [Batch 36/77] [D loss: 0.474640] [G loss: 1.137988]\n",
            "[Epoch 7/10] [Batch 37/77] [D loss: 0.672017] [G loss: 0.658917]\n",
            "[Epoch 7/10] [Batch 38/77] [D loss: 0.486057] [G loss: 1.699770]\n",
            "[Epoch 7/10] [Batch 39/77] [D loss: 0.613301] [G loss: 0.496997]\n",
            "[Epoch 7/10] [Batch 40/77] [D loss: 0.773207] [G loss: 1.735221]\n",
            "[Epoch 7/10] [Batch 41/77] [D loss: 0.852427] [G loss: 0.438415]\n",
            "[Epoch 7/10] [Batch 42/77] [D loss: 0.494379] [G loss: 0.626943]\n",
            "[Epoch 7/10] [Batch 43/77] [D loss: 0.639553] [G loss: 1.504938]\n",
            "[Epoch 7/10] [Batch 44/77] [D loss: 0.366818] [G loss: 0.912515]\n",
            "[Epoch 7/10] [Batch 45/77] [D loss: 0.397736] [G loss: 0.737183]\n",
            "[Epoch 7/10] [Batch 46/77] [D loss: 0.336249] [G loss: 1.031466]\n",
            "[Epoch 7/10] [Batch 47/77] [D loss: 0.367023] [G loss: 1.139868]\n",
            "[Epoch 7/10] [Batch 48/77] [D loss: 0.355383] [G loss: 0.941054]\n",
            "[Epoch 7/10] [Batch 49/77] [D loss: 0.399764] [G loss: 0.994748]\n",
            "[Epoch 7/10] [Batch 50/77] [D loss: 0.379740] [G loss: 0.889594]\n",
            "[Epoch 7/10] [Batch 51/77] [D loss: 0.438553] [G loss: 1.228572]\n",
            "[Epoch 7/10] [Batch 52/77] [D loss: 0.591700] [G loss: 0.623779]\n",
            "[Epoch 7/10] [Batch 53/77] [D loss: 0.763481] [G loss: 1.374451]\n",
            "[Epoch 7/10] [Batch 54/77] [D loss: 0.976828] [G loss: 0.219755]\n",
            "[Epoch 7/10] [Batch 55/77] [D loss: 0.468582] [G loss: 0.626263]\n",
            "[Epoch 7/10] [Batch 56/77] [D loss: 0.614414] [G loss: 1.848829]\n",
            "[Epoch 7/10] [Batch 57/77] [D loss: 0.397654] [G loss: 0.743070]\n",
            "[Epoch 7/10] [Batch 58/77] [D loss: 0.463450] [G loss: 0.590097]\n",
            "[Epoch 7/10] [Batch 59/77] [D loss: 0.379182] [G loss: 1.193459]\n",
            "[Epoch 7/10] [Batch 60/77] [D loss: 0.411987] [G loss: 1.008695]\n",
            "[Epoch 7/10] [Batch 61/77] [D loss: 0.469305] [G loss: 0.717830]\n",
            "[Epoch 7/10] [Batch 62/77] [D loss: 0.375745] [G loss: 0.886897]\n",
            "[Epoch 7/10] [Batch 63/77] [D loss: 0.305716] [G loss: 1.215948]\n",
            "[Epoch 7/10] [Batch 64/77] [D loss: 0.364006] [G loss: 1.077644]\n",
            "[Epoch 7/10] [Batch 65/77] [D loss: 0.466999] [G loss: 0.728606]\n",
            "[Epoch 7/10] [Batch 66/77] [D loss: 0.485090] [G loss: 1.071861]\n",
            "[Epoch 7/10] [Batch 67/77] [D loss: 0.659859] [G loss: 0.543541]\n",
            "[Epoch 7/10] [Batch 68/77] [D loss: 0.915936] [G loss: 1.824988]\n",
            "[Epoch 7/10] [Batch 69/77] [D loss: 0.827776] [G loss: 0.364068]\n",
            "[Epoch 7/10] [Batch 70/77] [D loss: 0.516971] [G loss: 0.572709]\n",
            "[Epoch 7/10] [Batch 71/77] [D loss: 0.426934] [G loss: 1.369824]\n",
            "[Epoch 7/10] [Batch 72/77] [D loss: 0.473915] [G loss: 1.125582]\n",
            "[Epoch 7/10] [Batch 73/77] [D loss: 0.561120] [G loss: 0.601384]\n",
            "[Epoch 7/10] [Batch 74/77] [D loss: 0.440214] [G loss: 0.838406]\n",
            "[Epoch 7/10] [Batch 75/77] [D loss: 0.420537] [G loss: 1.007567]\n",
            "[Epoch 7/10] [Batch 76/77] [D loss: 0.570911] [G loss: 0.600882]\n",
            "[Epoch 8/10] [Batch 0/77] [D loss: 0.784211] [G loss: 1.703417]\n",
            "[Epoch 8/10] [Batch 1/77] [D loss: 0.988538] [G loss: 0.299281]\n",
            "[Epoch 8/10] [Batch 2/77] [D loss: 0.487302] [G loss: 0.870846]\n",
            "[Epoch 8/10] [Batch 3/77] [D loss: 0.467318] [G loss: 1.116201]\n",
            "[Epoch 8/10] [Batch 4/77] [D loss: 0.440670] [G loss: 0.779988]\n",
            "[Epoch 8/10] [Batch 5/77] [D loss: 0.472939] [G loss: 0.623662]\n",
            "[Epoch 8/10] [Batch 6/77] [D loss: 0.470385] [G loss: 1.045720]\n",
            "[Epoch 8/10] [Batch 7/77] [D loss: 0.482216] [G loss: 0.866271]\n",
            "[Epoch 8/10] [Batch 8/77] [D loss: 0.504217] [G loss: 0.576219]\n",
            "[Epoch 8/10] [Batch 9/77] [D loss: 0.428789] [G loss: 0.751325]\n",
            "[Epoch 8/10] [Batch 10/77] [D loss: 0.479157] [G loss: 0.923646]\n",
            "[Epoch 8/10] [Batch 11/77] [D loss: 0.451656] [G loss: 0.671062]\n",
            "[Epoch 8/10] [Batch 12/77] [D loss: 0.410871] [G loss: 1.130448]\n",
            "[Epoch 8/10] [Batch 13/77] [D loss: 0.380042] [G loss: 1.008278]\n",
            "[Epoch 8/10] [Batch 14/77] [D loss: 0.449563] [G loss: 1.054158]\n",
            "[Epoch 8/10] [Batch 15/77] [D loss: 0.572866] [G loss: 0.540900]\n",
            "[Epoch 8/10] [Batch 16/77] [D loss: 0.614114] [G loss: 1.297015]\n",
            "[Epoch 8/10] [Batch 17/77] [D loss: 0.544501] [G loss: 0.617597]\n",
            "[Epoch 8/10] [Batch 18/77] [D loss: 0.530855] [G loss: 0.805452]\n",
            "[Epoch 8/10] [Batch 19/77] [D loss: 0.529557] [G loss: 1.091757]\n",
            "[Epoch 8/10] [Batch 20/77] [D loss: 0.617622] [G loss: 0.739062]\n",
            "[Epoch 8/10] [Batch 21/77] [D loss: 0.470971] [G loss: 1.285662]\n",
            "[Epoch 8/10] [Batch 22/77] [D loss: 0.525527] [G loss: 1.670472]\n",
            "[Epoch 8/10] [Batch 23/77] [D loss: 0.680626] [G loss: 0.468183]\n",
            "[Epoch 8/10] [Batch 24/77] [D loss: 0.371406] [G loss: 1.183787]\n",
            "[Epoch 8/10] [Batch 25/77] [D loss: 0.747639] [G loss: 1.258261]\n",
            "[Epoch 8/10] [Batch 26/77] [D loss: 0.757115] [G loss: 0.492613]\n",
            "[Epoch 8/10] [Batch 27/77] [D loss: 0.534903] [G loss: 1.175573]\n",
            "[Epoch 8/10] [Batch 28/77] [D loss: 0.411146] [G loss: 0.820078]\n",
            "[Epoch 8/10] [Batch 29/77] [D loss: 0.434056] [G loss: 0.983206]\n",
            "[Epoch 8/10] [Batch 30/77] [D loss: 0.421324] [G loss: 1.041144]\n",
            "[Epoch 8/10] [Batch 31/77] [D loss: 0.505750] [G loss: 0.867481]\n",
            "[Epoch 8/10] [Batch 32/77] [D loss: 0.453471] [G loss: 0.760954]\n",
            "[Epoch 8/10] [Batch 33/77] [D loss: 0.466868] [G loss: 1.123011]\n",
            "[Epoch 8/10] [Batch 34/77] [D loss: 0.593215] [G loss: 0.601442]\n",
            "[Epoch 8/10] [Batch 35/77] [D loss: 0.494434] [G loss: 1.186489]\n",
            "[Epoch 8/10] [Batch 36/77] [D loss: 0.503646] [G loss: 1.007636]\n",
            "[Epoch 8/10] [Batch 37/77] [D loss: 0.811255] [G loss: 0.317364]\n",
            "[Epoch 8/10] [Batch 38/77] [D loss: 1.007862] [G loss: 1.777816]\n",
            "[Epoch 8/10] [Batch 39/77] [D loss: 0.892030] [G loss: 0.252990]\n",
            "[Epoch 8/10] [Batch 40/77] [D loss: 0.490341] [G loss: 0.685930]\n",
            "[Epoch 8/10] [Batch 41/77] [D loss: 0.663453] [G loss: 1.677618]\n",
            "[Epoch 8/10] [Batch 42/77] [D loss: 0.441086] [G loss: 0.688760]\n",
            "[Epoch 8/10] [Batch 43/77] [D loss: 0.461732] [G loss: 0.897939]\n",
            "[Epoch 8/10] [Batch 44/77] [D loss: 0.357348] [G loss: 1.014821]\n",
            "[Epoch 8/10] [Batch 45/77] [D loss: 0.415766] [G loss: 0.813468]\n",
            "[Epoch 8/10] [Batch 46/77] [D loss: 0.514912] [G loss: 1.098467]\n",
            "[Epoch 8/10] [Batch 47/77] [D loss: 0.890069] [G loss: 0.513756]\n",
            "[Epoch 8/10] [Batch 48/77] [D loss: 0.848640] [G loss: 1.927040]\n",
            "[Epoch 8/10] [Batch 49/77] [D loss: 0.938509] [G loss: 0.260231]\n",
            "[Epoch 8/10] [Batch 50/77] [D loss: 0.331629] [G loss: 1.029760]\n",
            "[Epoch 8/10] [Batch 51/77] [D loss: 0.536055] [G loss: 1.690115]\n",
            "[Epoch 8/10] [Batch 52/77] [D loss: 0.561799] [G loss: 0.516986]\n",
            "[Epoch 8/10] [Batch 53/77] [D loss: 0.469829] [G loss: 0.827956]\n",
            "[Epoch 8/10] [Batch 54/77] [D loss: 0.516422] [G loss: 1.135471]\n",
            "[Epoch 8/10] [Batch 55/77] [D loss: 0.506006] [G loss: 0.607950]\n",
            "[Epoch 8/10] [Batch 56/77] [D loss: 0.412677] [G loss: 0.863993]\n",
            "[Epoch 8/10] [Batch 57/77] [D loss: 0.490157] [G loss: 1.228502]\n",
            "[Epoch 8/10] [Batch 58/77] [D loss: 0.355196] [G loss: 0.856926]\n",
            "[Epoch 8/10] [Batch 59/77] [D loss: 0.406895] [G loss: 1.144530]\n",
            "[Epoch 8/10] [Batch 60/77] [D loss: 0.310969] [G loss: 1.123364]\n",
            "[Epoch 8/10] [Batch 61/77] [D loss: 0.284022] [G loss: 1.138509]\n",
            "[Epoch 8/10] [Batch 62/77] [D loss: 0.386159] [G loss: 1.189777]\n",
            "[Epoch 8/10] [Batch 63/77] [D loss: 0.574951] [G loss: 0.774585]\n",
            "[Epoch 8/10] [Batch 64/77] [D loss: 0.625837] [G loss: 0.934718]\n",
            "[Epoch 8/10] [Batch 65/77] [D loss: 0.611136] [G loss: 0.595566]\n",
            "[Epoch 8/10] [Batch 66/77] [D loss: 0.620755] [G loss: 1.552971]\n",
            "[Epoch 8/10] [Batch 67/77] [D loss: 0.635980] [G loss: 0.508222]\n",
            "[Epoch 8/10] [Batch 68/77] [D loss: 0.382885] [G loss: 2.200526]\n",
            "[Epoch 8/10] [Batch 69/77] [D loss: 0.336674] [G loss: 0.988973]\n",
            "[Epoch 8/10] [Batch 70/77] [D loss: 0.403940] [G loss: 1.240337]\n",
            "[Epoch 8/10] [Batch 71/77] [D loss: 0.633450] [G loss: 0.794237]\n",
            "[Epoch 8/10] [Batch 72/77] [D loss: 0.590162] [G loss: 0.468072]\n",
            "[Epoch 8/10] [Batch 73/77] [D loss: 1.123370] [G loss: 1.402559]\n",
            "[Epoch 8/10] [Batch 74/77] [D loss: 0.909339] [G loss: 0.361822]\n",
            "[Epoch 8/10] [Batch 75/77] [D loss: 0.470704] [G loss: 1.630989]\n",
            "[Epoch 8/10] [Batch 76/77] [D loss: 0.327094] [G loss: 1.382966]\n",
            "[Epoch 9/10] [Batch 0/77] [D loss: 0.415850] [G loss: 0.775046]\n",
            "[Epoch 9/10] [Batch 1/77] [D loss: 0.428508] [G loss: 1.232975]\n",
            "[Epoch 9/10] [Batch 2/77] [D loss: 0.519313] [G loss: 0.551101]\n",
            "[Epoch 9/10] [Batch 3/77] [D loss: 0.438506] [G loss: 1.537268]\n",
            "[Epoch 9/10] [Batch 4/77] [D loss: 0.521471] [G loss: 0.604941]\n",
            "[Epoch 9/10] [Batch 5/77] [D loss: 0.473915] [G loss: 0.757147]\n",
            "[Epoch 9/10] [Batch 6/77] [D loss: 0.627304] [G loss: 0.906359]\n",
            "[Epoch 9/10] [Batch 7/77] [D loss: 0.629303] [G loss: 0.445272]\n",
            "[Epoch 9/10] [Batch 8/77] [D loss: 0.581730] [G loss: 0.902568]\n",
            "[Epoch 9/10] [Batch 9/77] [D loss: 0.495518] [G loss: 0.798463]\n",
            "[Epoch 9/10] [Batch 10/77] [D loss: 0.545898] [G loss: 0.844826]\n",
            "[Epoch 9/10] [Batch 11/77] [D loss: 0.385979] [G loss: 0.932612]\n",
            "[Epoch 9/10] [Batch 12/77] [D loss: 0.632283] [G loss: 1.689872]\n",
            "[Epoch 9/10] [Batch 13/77] [D loss: 1.748945] [G loss: 0.124160]\n",
            "[Epoch 9/10] [Batch 14/77] [D loss: 0.916474] [G loss: 2.659259]\n",
            "[Epoch 9/10] [Batch 15/77] [D loss: 0.464175] [G loss: 0.844209]\n",
            "[Epoch 9/10] [Batch 16/77] [D loss: 0.680234] [G loss: 0.389985]\n",
            "[Epoch 9/10] [Batch 17/77] [D loss: 0.333314] [G loss: 1.109034]\n",
            "[Epoch 9/10] [Batch 18/77] [D loss: 0.601025] [G loss: 1.671121]\n",
            "[Epoch 9/10] [Batch 19/77] [D loss: 0.510502] [G loss: 0.696616]\n",
            "[Epoch 9/10] [Batch 20/77] [D loss: 0.588406] [G loss: 0.505731]\n",
            "[Epoch 9/10] [Batch 21/77] [D loss: 0.546857] [G loss: 1.123159]\n",
            "[Epoch 9/10] [Batch 22/77] [D loss: 0.522245] [G loss: 0.731993]\n",
            "[Epoch 9/10] [Batch 23/77] [D loss: 0.439073] [G loss: 0.958515]\n",
            "[Epoch 9/10] [Batch 24/77] [D loss: 0.422297] [G loss: 1.182307]\n",
            "[Epoch 9/10] [Batch 25/77] [D loss: 0.455615] [G loss: 0.885326]\n",
            "[Epoch 9/10] [Batch 26/77] [D loss: 0.415330] [G loss: 0.974490]\n",
            "[Epoch 9/10] [Batch 27/77] [D loss: 0.475088] [G loss: 1.037577]\n",
            "[Epoch 9/10] [Batch 28/77] [D loss: 0.586920] [G loss: 0.763282]\n",
            "[Epoch 9/10] [Batch 29/77] [D loss: 0.537208] [G loss: 0.970129]\n",
            "[Epoch 9/10] [Batch 30/77] [D loss: 0.582408] [G loss: 0.635314]\n",
            "[Epoch 9/10] [Batch 31/77] [D loss: 0.675336] [G loss: 1.943692]\n",
            "[Epoch 9/10] [Batch 32/77] [D loss: 0.674652] [G loss: 0.377175]\n",
            "[Epoch 9/10] [Batch 33/77] [D loss: 0.459416] [G loss: 1.150742]\n",
            "[Epoch 9/10] [Batch 34/77] [D loss: 0.324218] [G loss: 1.455713]\n",
            "[Epoch 9/10] [Batch 35/77] [D loss: 0.348132] [G loss: 1.651391]\n",
            "[Epoch 9/10] [Batch 36/77] [D loss: 0.650807] [G loss: 0.415545]\n",
            "[Epoch 9/10] [Batch 37/77] [D loss: 0.622201] [G loss: 1.400822]\n",
            "[Epoch 9/10] [Batch 38/77] [D loss: 0.513872] [G loss: 0.710479]\n",
            "[Epoch 9/10] [Batch 39/77] [D loss: 0.400619] [G loss: 0.918466]\n",
            "[Epoch 9/10] [Batch 40/77] [D loss: 0.342285] [G loss: 1.324437]\n",
            "[Epoch 9/10] [Batch 41/77] [D loss: 0.509403] [G loss: 0.801253]\n",
            "[Epoch 9/10] [Batch 42/77] [D loss: 0.500868] [G loss: 1.154817]\n",
            "[Epoch 9/10] [Batch 43/77] [D loss: 0.603896] [G loss: 0.749421]\n",
            "[Epoch 9/10] [Batch 44/77] [D loss: 0.553286] [G loss: 1.199359]\n",
            "[Epoch 9/10] [Batch 45/77] [D loss: 0.521907] [G loss: 0.677977]\n",
            "[Epoch 9/10] [Batch 46/77] [D loss: 0.514327] [G loss: 0.830472]\n",
            "[Epoch 9/10] [Batch 47/77] [D loss: 0.520360] [G loss: 0.918645]\n",
            "[Epoch 9/10] [Batch 48/77] [D loss: 0.559481] [G loss: 0.673690]\n",
            "[Epoch 9/10] [Batch 49/77] [D loss: 0.483852] [G loss: 1.562101]\n",
            "[Epoch 9/10] [Batch 50/77] [D loss: 0.754453] [G loss: 0.429983]\n",
            "[Epoch 9/10] [Batch 51/77] [D loss: 0.882752] [G loss: 2.319542]\n",
            "[Epoch 9/10] [Batch 52/77] [D loss: 1.031636] [G loss: 0.236244]\n",
            "[Epoch 9/10] [Batch 53/77] [D loss: 0.530224] [G loss: 1.041429]\n",
            "[Epoch 9/10] [Batch 54/77] [D loss: 0.525611] [G loss: 1.864764]\n",
            "[Epoch 9/10] [Batch 55/77] [D loss: 0.436539] [G loss: 0.822208]\n",
            "[Epoch 9/10] [Batch 56/77] [D loss: 0.472636] [G loss: 0.622350]\n",
            "[Epoch 9/10] [Batch 57/77] [D loss: 0.445831] [G loss: 1.105512]\n",
            "[Epoch 9/10] [Batch 58/77] [D loss: 0.408250] [G loss: 0.787147]\n",
            "[Epoch 9/10] [Batch 59/77] [D loss: 0.427440] [G loss: 1.150971]\n",
            "[Epoch 9/10] [Batch 60/77] [D loss: 0.450570] [G loss: 0.854637]\n",
            "[Epoch 9/10] [Batch 61/77] [D loss: 0.478937] [G loss: 0.991103]\n",
            "[Epoch 9/10] [Batch 62/77] [D loss: 0.534244] [G loss: 0.566851]\n",
            "[Epoch 9/10] [Batch 63/77] [D loss: 0.830468] [G loss: 1.968068]\n",
            "[Epoch 9/10] [Batch 64/77] [D loss: 0.668722] [G loss: 0.391299]\n",
            "[Epoch 9/10] [Batch 65/77] [D loss: 0.459448] [G loss: 0.738355]\n",
            "[Epoch 9/10] [Batch 66/77] [D loss: 0.521205] [G loss: 1.551915]\n",
            "[Epoch 9/10] [Batch 67/77] [D loss: 0.459768] [G loss: 0.826435]\n",
            "[Epoch 9/10] [Batch 68/77] [D loss: 0.553610] [G loss: 0.664151]\n",
            "[Epoch 9/10] [Batch 69/77] [D loss: 0.477769] [G loss: 1.595058]\n",
            "[Epoch 9/10] [Batch 70/77] [D loss: 0.354287] [G loss: 0.925967]\n",
            "[Epoch 9/10] [Batch 71/77] [D loss: 0.485557] [G loss: 1.273812]\n",
            "[Epoch 9/10] [Batch 72/77] [D loss: 0.477168] [G loss: 0.645326]\n",
            "[Epoch 9/10] [Batch 73/77] [D loss: 0.432390] [G loss: 1.377829]\n",
            "[Epoch 9/10] [Batch 74/77] [D loss: 0.536711] [G loss: 0.554420]\n",
            "[Epoch 9/10] [Batch 75/77] [D loss: 0.771161] [G loss: 1.968830]\n",
            "[Epoch 9/10] [Batch 76/77] [D loss: 0.811314] [G loss: 0.459252]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yHit7l2yke8O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}